# ğŸ§  Local LLM Chatbot with History --- Powered by Ollama & Streamlit

A lightweight, privacy-focused AI chatbot that runs **completely
locally** using **Ollama**.\
This project includes:

-   ğŸš€ Local inference using the Ollama LLM\
-   ğŸ’¬ Chat history (persistent storage in JSON)\
-   ğŸŒ Streamlit UI for clean and fast interactions\
-   âš¡ Modular backend architecture with APIs\
-   ğŸ”§ Easy to customize, extend, and run locally

Perfect for beginners learning **Ollama**, **local LLM workflows**,
**Streamlit**, and **API design**.

------------------------------------------------------------------------

## âœ¨ Features

### ğŸ”¹ 1. Local LLM Powered by Ollama

The chatbot uses an Ollama model (defaults to `llama3`) and works
**fully offline**.

### ğŸ”¹ 2. Chat History (Persistent)

The entire conversation is stored in:

    history.json

### ğŸ”¹ 3. Streamlit UI

A smooth, clean interface to chat with the model.

### ğŸ”¹ 4. FastAPI Backend (Optional)

Backend API that handles: - Generating responses - Storing messages -
Retrieving chat history

### ğŸ”¹ 5. Easy Setup

Just run:

    uvicorn main:app
    streamlit run ui.py

------------------------------------------------------------------------

## ğŸ“‚ Project Structure

    ğŸ“¦ ollama-chatbot
     â”£ ğŸ“œ main.py
     â”£ ğŸ“œ chat_history.json
     â”£ ğŸ“œ ui.py
     â”£ ğŸ“œ requirements.txt
     â”— ğŸ“œ README.md

------------------------------------------------------------------------

## ğŸ› ï¸ Installation

### 1ï¸âƒ£ Install Ollama

https://ollama.com/download

    ollama pull llama3

### 2ï¸âƒ£ Clone repository

    git clone https://github.com/yourusername/ollama-chatbot.git
    cd ollama-chatbot

### 3ï¸âƒ£ Install dependencies

    pip install -r requirements.txt

------------------------------------------------------------------------

## â–¶ï¸ Running

Start backend:

    uvicorn main:app --reload

Start UI:

    streamlit run ui.py

------------------------------------------------------------------------

## ğŸ“¡ API Endpoints

  Method   Endpoint      Description
  -------- ------------- ----------------
  POST     `/generate`   Generate reply
  GET      `/history`    Fetch history

------------------------------------------------------------------------

## ğŸš€ Future Enhancements

-   RAG\
-   PDF/Text upload\
-   Multi-model switching\
-   Voice support

------------------------------------------------------------------------

## ğŸ¤ Contributing

PRs welcome.

------------------------------------------------------------------------

## ğŸ“œ License

MIT License.
